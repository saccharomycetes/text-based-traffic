{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function of create declearitive sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The car waits for a pedestrian to cross the road.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def create_declearitive(sent):\n",
    "    sent = sent.lower()\n",
    "    doc = nlp(sent)\n",
    "    if str(doc[0]) == \"because\" or str(doc[0]) == \"as\" or str(doc[0]) == \"since\" or str(doc[0]) == \"so\":\n",
    "        word = str(doc[0]) if sent.lower().find(\"so that\") == -1 else \"so that\"\n",
    "        return_sent = sent.replace(word,\"\",1)[1:].lower()\n",
    "    elif str(doc[0]) == \"to\":\n",
    "        return_sent = \"The car wants \" + sent.lower()\n",
    "    elif str(doc[0]) == \"at\" or str(doc[0]) == \"for\" or str(doc[0]) == \"due\":\n",
    "        word = \"due to\" if str(doc[0]) == \"due\" else str(doc[0])\n",
    "        return_sent = \"There is\" + sent.lower().replace(word, \"\", 1)\n",
    "    elif str(doc[0]) == \"while\":\n",
    "        if doc[1].pos_ == \"PRON\":\n",
    "            return_sent = sent.replace(\"while\",\"\",1)[1:].lower()\n",
    "        else:\n",
    "            return_sent = sent.replace(\"while\",\"the car is\",1).lower()\n",
    "    else:\n",
    "        return_sent = sent\n",
    "    return_sent = return_sent.lower().replace(\"it\", \"the car\", 1).replace(\"it's\", \"the car is\", 1)\n",
    "    return_sent = return_sent[0].upper() + return_sent[1:].lower()\n",
    "    return_sent = return_sent if return_sent[-1] == \".\" else return_sent + \".\"\n",
    "    return return_sent\n",
    "create_declearitive(\"while it waits for a pedestrian to cross the road.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get \"dataset\" with sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                     | 0/12997 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194955\n",
      "26523\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/bdd/raw.csv\")\n",
    "df = df.fillna(\"\")\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=\"cuda\")\n",
    "justi_names = [col for col in df.columns if \"justi\" in col]\n",
    "dataset = []\n",
    "premises = []\n",
    "hypothesises = []\n",
    "pbar = tqdm(total = df.shape[0], ncols = 100)\n",
    "for index, row in df.iterrows():\n",
    "    for j_colname in justi_names:\n",
    "        a_colname = j_colname.replace(\"justification\", \"action\")\n",
    "        i += 1\n",
    "        if row[j_colname] != \"\" and row[j_colname] != None and row[j_colname].find(\"unknown\") != 0 and len(row[a_colname])>5 and len(row[j_colname])>5:\n",
    "            \n",
    "            premise = create_declearitive(row[j_colname])\n",
    "            hypothesis = row[a_colname]\n",
    "            premises.append(premise)\n",
    "            hypothesises.append(hypothesis)\n",
    "            data = {}\n",
    "            data[\"premise\"] = premise\n",
    "            data[\"hypothesis\"] = hypothesis\n",
    "            data[\"indice\"] = (index, j_colname)\n",
    "            hypothesis_embed = model.encode(hypothesis)\n",
    "            premise_embed = model.encode(premise)\n",
    "            data[\"hembed\"] = hypothesis_embed\n",
    "            data[\"pembed\"] = premise_embed\n",
    "            dataset.append(data)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the too similar premises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4800/4800 [08:19<00:00,  9.61it/s]███████████| 12997/12997 [06:40<00:00, 41.40it/s]\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "new_dataset = []\n",
    "i = -1\n",
    "for data in tqdm(dataset):\n",
    "    for i, e in enumerate(embeds):\n",
    "        if util.pytorch_cos_sim(e, data[\"pembed\"]) > 0.9:\n",
    "            break\n",
    "    if i == len(embeds) - 1:\n",
    "        new_dataset.append(data)\n",
    "        embeds.append(data[\"pembed\"])\n",
    "dataset = new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build two multiple choice datasets, sampled by cause and effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 3139/3139 [00:26<00:00, 118.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 3139/3139 [00:03<00:00, 882.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_datas1 = []\n",
    "test_datas2 = []\n",
    "\n",
    "l = len(dataset)\n",
    "for data in tqdm(dataset, ncols=100):\n",
    "    hypothesis_embed = data[\"hembed\"]\n",
    "    distractors = []\n",
    "    embeds = []\n",
    "    embeds.append(hypothesis_embed)\n",
    "    while len(distractors) < 2:\n",
    "        num = random.sample(range(0,len(dataset)),1)[0]\n",
    "        distractor_data = dataset[num]\n",
    "        distractor = distractor_data[\"hypothesis\"]\n",
    "        if distractor not in distractors:\n",
    "            distractor_embed = distractor_data[\"hembed\"]\n",
    "            if_add = 1\n",
    "            for embed in embeds:\n",
    "                if util.pytorch_cos_sim(embed, distractor_embed) > 0.4:\n",
    "                    if_add = 0\n",
    "            if if_add == 1:\n",
    "                distractors.append(distractor)\n",
    "                embeds.append(distractor_embed)\n",
    "    test_data = {}\n",
    "    test_data[\"c\"] = data[\"premise\"]\n",
    "    test_data[\"e\"] = [distractors[0], distractors[1], data[\"hypothesis\"]]\n",
    "    test_data[\"answer\"] = 2\n",
    "    test_datas1.append(test_data)\n",
    "\n",
    "for data in tqdm(dataset, ncols=100):\n",
    "    premise_embed = data[\"pembed\"]\n",
    "    distractors = []\n",
    "    embeds = []\n",
    "    embeds.append(premise_embed)\n",
    "    while len(distractors) < 2:\n",
    "        num = random.sample(range(0,len(dataset)), 1)[0]\n",
    "        distractor_data = dataset[num]\n",
    "        distractor = distractor_data[\"premise\"]\n",
    "        if distractor not in distractors:\n",
    "            distractor_embed = distractor_data[\"pembed\"]\n",
    "            if_add = 1\n",
    "            for embed in embeds:\n",
    "                if util.pytorch_cos_sim(embed, distractor_embed) > 0.4:\n",
    "                    if_add = 0\n",
    "            if if_add == 1:\n",
    "                distractors.append(distractor)\n",
    "                embeds.append(distractor_embed)\n",
    "    test_data = {}\n",
    "    test_data[\"c\"] = [distractors[0], distractors[1], data[\"premise\"]]\n",
    "    test_data[\"e\"] = data[\"hypothesis\"]\n",
    "    test_data[\"answer\"] = 2\n",
    "    test_datas2.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/bdd/e.jsonl\", \"w\")as f:\n",
    "    for i, data in enumerate(test_datas1):\n",
    "        data[\"id\"] = i\n",
    "        f.write(json.dumps(data))\n",
    "        f.write(\"\\n\")\n",
    "with open(\"../../data/bdd/c.jsonl\", \"w\")as f:\n",
    "    for i, data in enumerate(test_datas2):\n",
    "        data[\"id\"] = i\n",
    "        f.write(json.dumps(data))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for deciding the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4311]])\n",
      "tensor([[0.2769]])\n",
      "tensor([[0.4761]])\n",
      "tensor([[0.3100]])\n",
      "tensor([[0.3847]])\n",
      "tensor([[0.3753]])\n",
      "tensor([[0.5299]])\n",
      "tensor([[0.5334]])\n",
      "tensor([[0.6020]])\n",
      "tensor([[0.6243]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "ori = \"The car slows to a stop\"\n",
    "sentences = [\"The vehicle is driving forward\",\n",
    "             \"The vehicle is cruising along the road\",\n",
    "             \"The car is driving forward\",\n",
    "             \"The car is cruising along the road\",\n",
    "             \"The car is steering to the right\",\n",
    "             \"The car makes a right hand turn with its windshield wipers on\",\n",
    "             \"The vehicle is motionless\", \n",
    "             \"The vehicle is not moving\",\n",
    "             \"The car is motionless\", \n",
    "             \"The car is not moving\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "oriembed = model.encode(ori)\n",
    "embeddings = model.encode(sentences)\n",
    "for e in embeddings:\n",
    "    print(util.cos_sim(oriembed, e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('jrenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bac62ed733118dd8de9c1e2917899fd0f24659b3827a5fdfb2405914a98de30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
